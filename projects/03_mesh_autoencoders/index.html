<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Anurag Ranjan | Mesh Autoencoders</title>
  <meta name="description" content="Anurag's personal and research website.
">

  <link rel="shortcut icon" href="///assets/img/favicon.ico">

  <link rel="stylesheet" href="///assets/css/main.css">
  <link rel="canonical" href="///projects/03_mesh_autoencoders/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <a href="/">
        <strong>Anurag</strong> Ranjan </a>
    </span>
    

    <nav class="site-nav">

      <div class="trigger">
        <!-- About -->
        <!--a class="page-link" href="///">about</a-->

        <!-- Blog -->
        <a class="page-link" href="///blog/">blog</a>

        <!-- Pages -->
        
          
        
          
            <a class="page-link" href="///bio/">bio</a>
          
        
          
            <a class="page-link" href="///media/">media</a>
          
        
          
            <a class="page-link" href="///projects/">projects</a>
          
        
          
            <a class="page-link" href="///publications/">publications</a>
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="///assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Mesh Autoencoders</h1>
    <h5 class="post-description">Generate faces, clothing and more using mesh convolutional autoencoders</h5>
  </header>

  <article class="post-content Mesh Autoencoders clearfix">
    <div class="img_row">
    <img class="col two obj-top" src="/assets/img/coma_samples.jpg" alt="" title="Faces using CoMA" />
    <img class="col one obj-top obj-right" src="/assets/img/autoenclother.jpg" alt="" title="Clothing using Mesh-VAE-GAN" />
</div>
<div class="col three caption">
    Generated faces using Convolutional Mesh Autoencoders and dressing humans with a GAN added to the CoMA framework.
</div>

<h3 id="learning-to-generate-faces">Learning to Generate Faces</h3>

<p><a class="citation" href="#ranjan2018generating">(Ranjan, Bolkart, Sanyal, &amp; Black, 2018)</a></p>

<p>Learned 3D representations of human faces are useful for computer vision problems such as 3D face tracking and reconstruction from images, as well as graphics applications such as character generation and animation. Traditional models learn a latent representation of a face using linear subspaces or higher-order tensor generalizations. Due to this linearity, they can not capture extreme deformations and non-linear expressions.</p>

<p>To address this, we introduce a versatile model that learns a non-linear representation of a face using spectral convolutions on a mesh surface. We introduce mesh sampling operations that enable a hierarchical mesh representation that captures non-linear variations in shape and expression at multiple scales within the model. In a variational setting, our model samples diverse realistic 3D faces from a multivariate Gaussian distribution. Our training data consists of 20,466 meshes of extreme expressions captured over 12 different subjects. Despite limited training data, our trained model outperforms state-of-the-art face models with 50% lower reconstruction error, while using 75% fewer parameters. We also show that, replacing the expression space of an existing state-of-the-art face model with our autoencoder, achieves a lower reconstruction error.</p>

<h3 id="dressing-humans-in-3d">Dressing Humans in 3D</h3>

<p><a class="citation" href="#ma2020dressing">(Ma et al., 2020)</a></p>

<p>Three-dimensional human body models are widely used in the analysis of human pose and motion. Existing models, however, are learned from minimally-clothed humans and thus do not capture the complexity of dressed humans in common images and videos. To address this, we learn a generative 3D mesh model of clothing from 3D scans of people with varying pose. Going beyond previous work, our generative model is conditioned on different clothing types, giving the ability to dress different body shapes in a variety of clothing. To do so, we train a conditional Mesh-VAE-GAN on clothing displacements from a 3D SMPL body model.</p>

<p>This generative clothing model enables us to sample various types of clothing, in novel poses, on top of SMPL. With a focus on clothing geometry, the model captures both global shape and local structure, effectively extending the SMPL model to add clothing. To our knowledge, this is the first conditional VAE-GAN that works on 3D meshes. For clothing specifically, it is the first such model that directly dresses 3D human body meshes and generalizes to different poses.</p>

<ol class="bibliography"><li>

<div id="ma2020dressing">
  <div class="col two">
  
    <span class="title">Learning to Dress 3D People in Generative Clothing</span>
    <span class="author">
      
        
          
            
              <a href="https://www.is.mpg.de/person/qma" target="_blank">Qianli Ma</a>,
            
          
        
      
        
          
            
              Jinlong Yang,
            
          
        
      
        
          
            <em>Anurag Ranjan</em>,
          
        
      
        
          
            
              Sergi Pujades,
            
          
        
      
        
          
            
              Gerard Pons-Moll,
            
          
        
      
        
          
            
              <a href="https://ps.is.tuebingen.mpg.de/person/stang" target="_blank">Siyu Tang</a>,
            
          
        
      
        
          and
          
            
              <a href="https://ps.is.mpg.de/~black" target="_blank">Michael J. Black</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Computer Vision and Pattern Recognition (CVPR)</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  <!-- 
    [<a class="abstract">Abs</a>]
   -->
  
    [<a href="http://arxiv.org/abs/1907.13615" target="_blank">arXiv</a>]
  
  
  
  
  
  
  
    [<a href="https://github.com/QianliM/CAPE" target="_blank">Code</a>]
  
  
    [<a href="https://cape.is.tue.mpg.de/" target="_blank">URL</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <div>
    <p>CAPE is a Graph-CNN based generative model for dressing 3D meshes of human body. It is compatible with the popular body model, SMPL, and can generalize to diverse body shapes and body poses. It is designed to be "plug-and-play" for many applications that already use SMPL. The CAPE Dataset provides SMPL mesh registration of 4D scans of people in clothing, along with registered scans of the ground truth body shapes under clothing.</p>
  </div>
  

</div>

  
    <img class="col one" src="/assets/img/autoenclother.jpg" />
  

</div>
</li>
<li>

<div id="ranjan2018generating">
  <div class="col two">
  
    <span class="title">Generating 3D faces using convolutional mesh autoencoders</span>
    <span class="author">
      
        
          
            <em>Anurag Ranjan</em>,
          
        
      
        
          
            
              <a href="https://sites.google.com/site/bolkartt/" target="_blank">Timo Bolkart</a>,
            
          
        
      
        
          
            
              <a href="https://ps.is.mpg.de/~ssanyal" target="_blank">Soubhik Sanyal</a>,
            
          
        
      
        
          and
          
            
              <a href="https://ps.is.mpg.de/~black" target="_blank">Michael J Black</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In European Conference on Computer Vision (ECCV)</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  <!-- 
    [<a class="abstract">Abs</a>]
   -->
  
    [<a href="http://arxiv.org/abs/1807.10267" target="_blank">arXiv</a>]
  
  
  
  
  
  
  
    [<a href="https://github.com/anuragranj/coma" target="_blank">Code</a>]
  
  
    [<a href="http://coma.is.tue.mpg.de/" target="_blank">URL</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <div>
    <p>A non-linear model for generating 3D faces using a Convolutional Autoencoder that operates directly on meshes. Our model is state of the art in generating diverse range of 3D facial meshes.</p>
  </div>
  

</div>

  
    <img class="col one" src="/assets/img/coma_samples.jpg" />
  

</div>
</li></ol>

  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2023 Anurag Ranjan.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="///assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
<script src="///assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="///assets/css/font-awesome.min.css">
<link rel="stylesheet" href="///assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXX-X', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
