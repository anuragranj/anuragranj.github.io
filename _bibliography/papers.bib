---
---

@string{aps = {American Physical Society,}}

@article{einstein1905movement,
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.,},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@article{nunez2021lcs,
  title={LCS: Learning Compressible Subspaces for Adaptive Network Compression at Inference Time},
  author={Nunez, Elvis and Horton, Maxwell and Prabhu, Anish and Ranjan, Anurag and Farhadi, Ali and Rastegari, Mohammad},
  journal={arXiv preprint arXiv:2110.04252},
  arXiv={2110.04252},
  img={/assets/img/lcs.jpg},
  year={2021}
}

@article{marin2021token,
  title={Token Pooling in Vision Transformers},
  author={Marin, Dmitrii and Chang, Jen-Hao Rick and Ranjan, Anurag and Prabhu, Anish and Rastegari, Mohammad and Tuzel, Oncel},
  arxiv={2110.03860},
  img={/assets/img/token_pooling.jpg},
  journal={arXiv preprint arXiv:2110.03860},
  year={2021}
}

@inproceedings{roberts2021hypersim,
  title={Hypersim: A photorealistic synthetic dataset for holistic indoor scene understanding},
  author={Roberts, Mike and Ramapuram, Jason and Ranjan, Anurag and Kumar, Atulit and Bautista, Miguel Angel and Paczan, Nathan and Webb, Russ and Susskind, Joshua M},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10912--10922},
  arxiv={2011.02523},
  code={https://github.com/apple/ml-hypersim},
  url={https://machinelearning.apple.com/research/hypersim},
  img={/assets/img/hypersim.jpg},
  abstract={Hypersim is a photorealistic synthetic dataset for holistic indoor scene understanding containing 77,400 images of 461 indoor scenes with detailed per-pixel labels and corresponding ground truth geometry.},
  year={2021}
}

@inproceedings{rruiz2020morphgan,
      title={MorphGAN: One-Shot Face Synthesis GAN for Detecting Recognition Bias}, 
      author={Nataniel Ruiz and Barry-John Theobald and Anurag Ranjan and Ahmed Hussein Abdelaziz and Nicholas Apostoloff},
      booktitle={arXiv},
      year={2020},
      arxiv={2012.05225},
      img={/assets/img/morphgan.gif},
      url={https://machinelearning.apple.com/research/morphgan},
      abstract={MorphGAN can animate any face and control using a 3D rig. It's one-shot and generalizes to in-the-wild unseen faces.},
}

@inproceedings{GIF2020,
    title = {{GIF}: Generative Interpretable Faces},
    author = {Ghosh, Partha and Gupta, Pravir Singh and Uziel, Roy and Ranjan, Anurag and Black, Michael J. and Bolkart, Timo},
    booktitle = {International Conference on 3D Vision (3DV)},
    year = {2020},
    arxiv = {2009.00149},
    url = {http://gif.is.tue.mpg.de/},
    code = {https://github.com/ParthaEth/GIF},
    img={/assets/img/gif.png},
    abstract={GIF generates realistic face images and animate them with a 3D face rig.},
}

@article{ranjan2020learning,
  title={Learning Multi-Human Optical Flow},
  author={Ranjan, Anurag and Hoffmann, David T and Tzionas, Dimitrios and Tang, Siyu and Romero, Javier and Black, Michael J},
  journal={International Journal of Computer Vision},
  pages={1--18},
  year={2020},
  publisher={Springer},
  arxiv={1910.11667},
  url={http://humanflow.is.tue.mpg.de/},
  img={/assets/img/multihumanflow.jpg},
}

@inproceedings{ma2020dressing,
  title = {Learning to Dress 3D People in Generative Clothing},
  author = {Ma, Qianli and Yang, Jinlong and Ranjan, Anurag and Pujades, Sergi and Pons-Moll, Gerard and Tang, Siyu and Black, Michael J.},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  pages = {6468-6477},
  publisher = {IEEE},
  year = {2020},
  arxiv={1907.13615},
  url={https://cape.is.tue.mpg.de/},
  code={https://github.com/QianliM/CAPE},
  img={/assets/img/autoenclother.jpg},
  abstract={CAPE is a Graph-CNN based generative model for dressing 3D meshes of human body. It is compatible with the popular body model, SMPL, and can generalize to diverse body shapes and body poses. It is designed to be "plug-and-play" for many applications that already use SMPL. The CAPE Dataset provides SMPL mesh registration of 4D scans of people in clothing, along with registered scans of the ground truth body shapes under clothing.},
}

@thesis{ranjan2019towards,
  title={Towards Geometric Understanding of Motion},
  author={Ranjan, Anurag},
  year={2019},
  school={University of Tuebingen Tuebingen},
  url={https://ps.is.tuebingen.mpg.de/publications/ranjan-thesis},
  img={https://ps.is.tuebingen.mpg.de/uploads/publication/image/22831/phdteaser.png},
}

@inproceedings{ranjan2019attacking,
  title={Attacking Optical Flow},
  author={Ranjan, Anurag and Janai, Joel and Geiger, Andreas and Black, Michael J},
  booktitle={International Conference on Computer Vision (ICCV)},
  pages={2404--2413},
  code={https://github.com/anuragranj/flowattack},
  abstract={Deep learning based optical flow methods are vulnerable to adversarial attacks. We show that it is very easy to attack these systems in real world by just placing a small printed patch in the scene.},
  url={https://flowattack.is.tuebingen.mpg.de/},
  arxiv={1910.10053},
  year={2019},
  img={/assets/img/attacking-OF-patch.png},
}

@inproceedings{ranjan2017optical,
  title={Optical flow estimation using a spatial pyramid network},
  author={Ranjan, Anurag and Black, Michael J},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={4161--4170},
  arxiv={1611.00850},
  url={http://spynet.is.tue.mpg.de/},
  code={https://github.com/anuragranj/spynet},
  year={2017},
  img={/assets/img/sintel_pyramid.png},
}

@inproceedings{ranjan2018generating,
  title={Generating 3D faces using convolutional mesh autoencoders},
  author={Ranjan, Anurag and Bolkart, Timo and Sanyal, Soubhik and Black, Michael J},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={704--720},
  abstract={A non-linear model for generating 3D faces using a Convolutional Autoencoder that operates directly on meshes. Our model is state of the art in generating diverse range of 3D facial meshes.},
  code={https://github.com/anuragranj/coma},
  url={http://coma.is.tue.mpg.de/},
  arxiv={1807.10267},
  year={2018},
  img={/assets/img/coma_samples.jpg}
}

@article{ranjan2018learning,
  title={Learning human optical flow},
  author={Ranjan, Anurag and Romero, Javier and Black, Michael J},
  journal={British Machine Vision Conference (BMVC)},
  abstract={Learning optical flow for humans is difficult. So, we created a synthetic dataset with realistic humans and trained a neural network on it.},
  code={https://github.com/anuragranj/humanflow},
  url={http://humanflow.is.tue.mpg.de/},
  arxiv={1806.05666},
  year={2018},
  img={/assets/img/humanflow.png},
}

@inproceedings{janai2018unsupervised,
  title={Unsupervised learning of multi-frame optical flow with occlusions},
  author={Janai, Joel and Guney, Fatma and Ranjan, Anurag and Black, Michael and Geiger, Andreas},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={690--706},
  abstract={We propose a framework for unsupervised learning of optical flow and occlusions over multiple frames. Our multi-frame, occlusion-sensitive formulation outperforms existing unsupervised two-frame methods and even produces results on par with some fully supervised methods.},
  code={https://github.com/anuragranj/back2future.pytorch},
  pdf={Janai2018ECCV.pdf},
  year={2018}
}

@inproceedings{bongale2012implementation,
  title={Implementation of 3D object recognition and tracking},
  author={Bongale, Pankaj and Ranjan, Anurag and Anand, Sahil},
  booktitle={International conference on Recent Advances in Computing and Software Systems (RACSS)},
  pages={77--79},
  pdf={bongale2012implementation.pdf},
  year={2012},
  organization={IEEE}
}

@inproceedings{ranjan2019competitive,
  title={Competitive Collaboration: Joint Unsupervised Learning of Depth, Camera Motion, Optical Flow and Motion Segmentation},
  author={Ranjan, Anurag and Jampani, Varun and Balles, Lukas and Kim, Kihwan and Sun, Deqing and Wulff, Jonas and Black, Michael J},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={12240--12249},
  arxiv={1805.09806},
  abstract={Unsupervised learning of several interconnected problems in low-level vision: single view depth prediction, camera motion estimation, optical flow and segmentation of a video into the static scene and moving regions.},
  code={https://github.com/anuragranj/cc},
  talk={https://developer.nvidia.com/gtc/2019/video/S9575},
  year={2019},
  img={/assets/img/joint_teaser.png},
}

@inproceedings{neog2016interactive,
  title={Interactive gaze driven animation of the eye region},
  author={Neog, Debanga R and Cardoso, Jo{\~a}o L and Ranjan, Anurag and Pai, Dinesh K},
  booktitle={International Conference on Web3D Technology},
  pages={51--59},
  year={2016},
  url={http://www.cs.ubc.ca/research/eyemoveweb3d16/},
  organization={ACM},
  img={/assets/img/faces.jpg},
}

@thesis{ranjan2015learning,
  title={Learning periorbital soft tissue motion},
  author={Ranjan, Anurag},
  year={2015},
  abstract={We model the soft tissues around the eyes that are associated with subtle and fast motions and convey emotions during facial expressions. Our data driven model that can efficiently learn and reproduce the complex motion of these periorbital soft tissues.},
  url={https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0166703},
  school={University of British Columbia,}
}

@misc{ray2019unsupervised,
  title={Unsupervised video segmentation},
  author={Ray, Benjamin and Ranjan, Anurag},
  year={2019},
  month=sep # "~3",
  publisher={Google Patents},
  url={https://patents.google.com/patent/US10402986B2/en},
  note={US Patent 10,402,986}
}

@inproceedings{cudeiro2019capture,
  title={Capture, Learning, and Synthesis of 3D Speaking Styles},
  author={Cudeiro, Daniel and Bolkart, Timo and Laidlaw, Cassidy and Ranjan, Anurag and Black, Michael J},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={10101--10111},
  arxiv={1905.03079},
  abstract={A neural network for generating 3D facial motion by using raw speech audio. Works on a veriety of unseen faces.},
  code={https://github.com/TimoBolkart/voca},
  url={https://voca.is.tue.mpg.de/},
  year={2019},
  img={/assets/img/voca.png},
}

@inproceedings{neog2017seeing,
  title={Seeing Skin in Reduced Coordinates},
  author={Neog, Debanga R and Ranjan, Anurag and Pai, Dinesh K},
  booktitle={IEEE International Conference on Automatic Face \& Gesture Recognition (FG)},
  pages={484--489},
  year={2017},
  url={http://www.cs.ubc.ca/research/seeingskininreducedcoordinates/},
  organization={IEEE}
}

@inproceedings{neog2015gaze,
  title={Gaze driven animation of eyes},
  author={Neog, Debanga Raj and Ranjan, Anurag and Cardoso, Jo{\~a}o L and Pai, Dinesh K},
  booktitle={ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
  pages={198--198},
  year={2015},
  pdf={Gaze_driven_animation.pdf},
  organization={ACM}
}


