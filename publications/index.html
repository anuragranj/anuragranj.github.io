<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>publications | Anurag  Ranjan</title>
    <meta name="author" content="Anurag  Ranjan">
    <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar.">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link rel="stylesheet" href="/about/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
    <!-- <link rel="stylesheet" href="/about/assets/css/mdb.min.css?62a43d1430ddb46fc4886f9d0e3b49b8"> -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="/about/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="/about/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/about/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://anuragranjan.com/about/publications/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="/about/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark">
    <script src="/about/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/about/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/about/"><span class="font-weight-bold">Anurag </span>Ranjan</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/about/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/about/bio/">bio</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/about/publications/">publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/about/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/about/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">

<h2 class="bibliography">2023</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/facelit.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/facelit.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/facelit.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/facelit.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="facelit.gif" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="ranjan2023facelit" class="col-sm-8">
        <!-- Title -->
        <div class="title">FaceLit: Neural 3D Relightable Faces</div>
        <!-- Author -->
        <div class="author">
        

        <em>Anurag Ranjan</em>, Kwang Moo Yi, Jen-Hao Rick Chang, and Oncel Tuzel</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/2303.15437" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/apple/ml-facelit" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"><img data-zoomable="" class="preview z-depth-1 rounded" src="https://github.com/apple/ml-pointersect/raw/main/assets/img/pointersect_preview.png"></div>

        <!-- Entry bib key -->
        <div id="chang2023pointersect" class="col-sm-8">
        <!-- Title -->
        <div class="title">Pointersect: Neural Rendering with Cloud-Ray Intersection</div>
        <!-- Author -->
        <div class="author">
        

        Jen-Hao Rick Chang, Wei-Yu Chen, <em>Anurag Ranjan</em>, Kwang Moo Yi, and Oncel Tuzel</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/2304.12390" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/apple/ml-pointersect" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"><img data-zoomable="" class="preview z-depth-1 rounded" src="https://github.com/apple/ml-fastvit/raw/main/docs/intro/acc_vs_latency.png"></div>

        <!-- Entry bib key -->
        <div id="vasu2023fastvit" class="col-sm-8">
        <!-- Title -->
        <div class="title">FastViT: A Fast Hybrid Vision Transformer using Structural Reparameterization</div>
        <!-- Author -->
        <div class="author">
        

        Pavan Kumar Anasosalu Vasu, James Gabriel, Jeff Zhu, Oncel Tuzel, and <em>Anurag Ranjan</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>International Conference on Computer Vision (ICCV)</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs//2303.14189" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/apple/ml-fastvit" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/finerecon-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/finerecon-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/finerecon-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/finerecon.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="finerecon.jpg" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="stier2023finerecon" class="col-sm-8">
        <!-- Title -->
        <div class="title">FineRecon: Depth-aware Feed-forward Network for Detailed 3D Reconstruction</div>
        <!-- Author -->
        <div class="author">
        

        Noah Stier, <em>Anurag Ranjan</em>, Alex Colburn, Yajie Yan, Liang Yang, Fangchang Ma, and Baptiste Angles</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>International Conference on Computer Vision (ICCV)</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/2304.01480" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/apple/ml-finerecon" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="mittal2022naturalistic" class="col-sm-8">
        <!-- Title -->
        <div class="title">Naturalistic Head Motion Generation from Speech</div>
        <!-- Author -->
        <div class="author">
        

        Trisha Mittal, Zakaria Aldeneh, Masha Fedzechkina, <em>Anurag Ranjan</em>, and Barry-John Theobald</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em></em> 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/arXiv:2210.14800" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2022</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/neuman_crop.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/neuman_crop.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/neuman_crop.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/neuman_crop.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="neuman_crop.gif" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="jiang2022neuman" class="col-sm-8">
        <!-- Title -->
        <div class="title">NeuMan: Neural Human Radiance Field from a Single Video</div>
        <!-- Author -->
        <div class="author">
        

        Wei Jiang, Kwang Moo Yi, Golnoosh Samei, Oncel Tuzel, and <em>Anurag Ranjan</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the European conference on computer vision (ECCV)</em>, 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2203.12575" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/apple/ml-neuman" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p> NeuMan is a NeRF representation of human together with the scene. From a single clip (&lt;100 frames), NeuMan can perform view synthesis of the scene without/with the human in novel poses.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"><img data-zoomable="" class="preview z-depth-1 rounded" src="https://raw.githubusercontent.com/apple/ml-mobileone/main/docs/accuracy_v_latency.jpg"></div>

        <!-- Entry bib key -->
        <div id="mobileone2022" class="col-sm-8">
        <!-- Title -->
        <div class="title">MobileOne: An Improved One millisecond Mobile Backbone</div>
        <!-- Author -->
        <div class="author">
        

        Pavan Kumar Anasosalu Vasu, James Gabriel, Jeff Zhu, Oncel Tuzel, and <em>Anurag Ranjan</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2206.04040" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/apple/ml-mobileone" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Fastest neural architecture on iPhone, runs under 1 ms.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/lcs-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/lcs-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/lcs-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/lcs.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="lcs.jpg" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="nunez2021lcs" class="col-sm-8">
        <!-- Title -->
        <div class="title">LCS: Learning Compressible Subspaces for Adaptive Network Compression at Inference Time</div>
        <!-- Author -->
        <div class="author">
        

        Elvis Nunez, Maxwell Horton, Anish Prabhu, <em>Anurag Ranjan</em>, Ali Farhadi, and Mohammad Rastegari</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em>, 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2110.04252" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>LCS is a method for training a "compressible subspace" of neural networks that contains a fine-grained spectrum of models that range from highly efficient to highly accurate. These models require no retraining, thus the subspace of models can be deployed entirely on-device to allow adaptive network compression at inference time.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/token_pooling-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/token_pooling-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/token_pooling-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/token_pooling.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="token_pooling.jpg" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="marin2021token" class="col-sm-8">
        <!-- Title -->
        <div class="title">Token Pooling in Vision Transformers</div>
        <!-- Author -->
        <div class="author">
        

        Dmitrii Marin, Jen-Hao Rick Chang, <em>Anurag Ranjan</em>, Anish Prabhu, Mohammad Rastegari, and Oncel Tuzel</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em>, 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2110.03860" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Token Pooling is a novel downsampling operator for vision transformers that efficiently exploits redundancies in the images and intermediate token representations. Applied to DeiT, it achieves the same ImageNet top-1 accuracy using 42% fewer computations.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="spin_eccv22" class="col-sm-8">
        <!-- Title -->
        <div class="title">SPIN: An Empirical Evaluation on Sharing Parameters of Isotropic Networks</div>
        <!-- Author -->
        <div class="author">
        

        Chien-Yu Lin, Anish Prabhu, Thomas Merth, Sachin Mehta, <em>Anurag Ranjan</em>, Maxwell Horton, and Mohammad Rastegari</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Proceedings of the European Conference on Computer Vision (ECCV)</em>, 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/2207.10237" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/apple/ml-spin" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2021</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/hypersim-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/hypersim-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/hypersim-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/hypersim.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="hypersim.jpg" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="roberts2021hypersim" class="col-sm-8">
        <!-- Title -->
        <div class="title">Hypersim: A photorealistic synthetic dataset for holistic indoor scene understanding</div>
        <!-- Author -->
        <div class="author">
        

        Mike Roberts, Jason Ramapuram, <em>Anurag Ranjan</em>, Atulit Kumar, Miguel Angel Bautista, Nathan Paczan, Russ Webb, and Joshua M Susskind</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2011.02523" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/apple/ml-hypersim" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Hypersim is a photorealistic synthetic dataset for holistic indoor scene understanding containing 77,400 images of 461 indoor scenes with detailed per-pixel labels and corresponding ground truth geometry.</p>
          </div>
        </div>
      </div>
</li></ol>
<h2 class="bibliography">2020</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/morphgan.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/morphgan.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/morphgan.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/morphgan.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="morphgan.gif" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="rruiz2020morphgan" class="col-sm-8">
        <!-- Title -->
        <div class="title">MorphGAN: One-Shot Face Synthesis GAN for Detecting Recognition Bias</div>
        <!-- Author -->
        <div class="author">
        

        Nataniel Ruiz, Barry-John Theobald, <em>Anurag Ranjan</em>, Ahmed Hussein Abdelaziz, and Nicholas Apostoloff</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In arXiv</em>, 2020
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2012.05225" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>MorphGAN can animate any face and control using a 3D rig. It’s one-shot and generalizes to in-the-wild unseen faces.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/gif.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="gif.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="GIF2020" class="col-sm-8">
        <!-- Title -->
        <div class="title">GIF: Generative Interpretable Faces</div>
        <!-- Author -->
        <div class="author">
        

        Partha Ghosh, Pravir Singh Gupta, Roy Uziel, <em>Anurag Ranjan</em>, Michael J. Black, and Timo Bolkart</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on 3D Vision (3DV)</em>, 2020
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2009.00149" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/ParthaEth/GIF" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>GIF generates realistic face images and animate them with a 3D face rig.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/multihumanflow-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/multihumanflow-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/multihumanflow-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/multihumanflow.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="multihumanflow.jpg" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="ranjan2020learning" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning Multi-Human Optical Flow</div>
        <!-- Author -->
        <div class="author">
        

        <em>Anurag Ranjan</em>, David T Hoffmann, Dimitrios Tzionas, Siyu Tang, Javier Romero, and Michael J Black</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>International Journal of Computer Vision</em>, 2020
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/1910.11667" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/cape.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/cape.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/cape.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/cape.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="cape.gif" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="ma2020dressing" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning to Dress 3D People in Generative Clothing</div>
        <!-- Author -->
        <div class="author">
        

        Qianli Ma, Jinlong Yang, <em>Anurag Ranjan</em>, Sergi Pujades, Gerard Pons-Moll, Siyu Tang, and Michael J. Black</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Computer Vision and Pattern Recognition (CVPR)</em>, 2020
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/1907.13615" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/QianliM/CAPE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>CAPE is a Graph-CNN based generative model for dressing 3D meshes of human body. It is compatible with the popular body model, SMPL, and can generalize to diverse body shapes and body poses. It is designed to be "plug-and-play" for many applications that already use SMPL. The CAPE Dataset provides SMPL mesh registration of 4D scans of people in clothing, along with registered scans of the ground truth body shapes under clothing.</p>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2019</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"><img data-zoomable="" class="preview z-depth-1 rounded" src="https://ps.is.tuebingen.mpg.de/uploads/publication/image/22831/phdteaser.png"></div>

        <!-- Entry bib key -->
        <div id="ranjan2019towards" class="col-sm-8">
        <!-- Title -->
        <div class="title">Towards Geometric Understanding of Motion</div>
        <!-- Author -->
        <div class="author">
        

        <em>Anurag Ranjan</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>University of Tuebingen Tuebingen</em>, 2019
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/attacking-OF-patch-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/attacking-OF-patch-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/attacking-OF-patch-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/attacking-OF-patch.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="attacking-OF-patch.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="ranjan2019attacking" class="col-sm-8">
        <!-- Title -->
        <div class="title">Attacking Optical Flow</div>
        <!-- Author -->
        <div class="author">
        

        <em>Anurag Ranjan</em>, Joel Janai, Andreas Geiger, and Michael J Black</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Computer Vision (ICCV)</em>, 2019
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/1910.10053" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/anuragranj/flowattack" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Deep learning based optical flow methods are vulnerable to adversarial attacks. We show that it is very easy to attack these systems in real world by just placing a small printed patch in the scene.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/joint_teaser-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/joint_teaser-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/joint_teaser-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/joint_teaser.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="joint_teaser.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="ranjan2019competitive" class="col-sm-8">
        <!-- Title -->
        <div class="title">Competitive Collaboration: Joint Unsupervised Learning of Depth, Camera Motion, Optical Flow and Motion Segmentation</div>
        <!-- Author -->
        <div class="author">
        

        <em>Anurag Ranjan</em>, Varun Jampani, Lukas Balles, Kihwan Kim, Deqing Sun, Jonas Wulff, and Michael J Black</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2019
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/1805.09806" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/anuragranj/cc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Unsupervised learning of several interconnected problems in low-level vision: single view depth prediction, camera motion estimation, optical flow and segmentation of a video into the static scene and moving regions.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="ray2019unsupervised" class="col-sm-8">
        <!-- Title -->
        <div class="title">Unsupervised video segmentation</div>
        <!-- Author -->
        <div class="author">
        

        Benjamin Ray, and <em>Anurag Ranjan</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          Sep 2019
        </div>
        <div class="periodical">
          US Patent 10,402,986
        </div>

          <!-- Links/Buttons -->
          <div class="links">
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/voca-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/voca-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/voca-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/voca.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="voca.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="cudeiro2019capture" class="col-sm-8">
        <!-- Title -->
        <div class="title">Capture, Learning, and Synthesis of 3D Speaking Styles</div>
        <!-- Author -->
        <div class="author">
        

        Daniel Cudeiro, Timo Bolkart, Cassidy Laidlaw, <em>Anurag Ranjan</em>, and Michael J Black</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, Sep 2019
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/1905.03079" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/TimoBolkart/voca" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A neural network for generating 3D facial motion by using raw speech audio. Works on a veriety of unseen faces.</p>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2018</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/coma_samples-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/coma_samples-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/coma_samples-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/coma_samples.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="coma_samples.jpg" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="ranjan2018generating" class="col-sm-8">
        <!-- Title -->
        <div class="title">Generating 3D faces using convolutional mesh autoencoders</div>
        <!-- Author -->
        <div class="author">
        

        <em>Anurag Ranjan</em>, Timo Bolkart, Soubhik Sanyal, and Michael J Black</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In European Conference on Computer Vision (ECCV)</em>, Sep 2018
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/1807.10267" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/anuragranj/coma" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A non-linear model for generating 3D faces using a Convolutional Autoencoder that operates directly on meshes. Our model is state of the art in generating diverse range of 3D facial meshes.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/humanflow-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/humanflow-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/humanflow-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/humanflow.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="humanflow.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="ranjan2018learning" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning human optical flow</div>
        <!-- Author -->
        <div class="author">
        

        <em>Anurag Ranjan</em>, Javier Romero, and Michael J Black</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>British Machine Vision Conference (BMVC)</em>, Sep 2018
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/1806.05666" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/anuragranj/humanflow" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Learning optical flow for humans is difficult. So, we created a synthetic dataset with realistic humans and trained a neural network on it.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="janai2018unsupervised" class="col-sm-8">
        <!-- Title -->
        <div class="title">Unsupervised learning of multi-frame optical flow with occlusions</div>
        <!-- Author -->
        <div class="author">
        

        Joel Janai, Fatma Guney, <em>Anurag Ranjan</em>, Michael Black, and Andreas Geiger</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In European Conference on Computer Vision (ECCV)</em>, Sep 2018
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="/about/assets/pdf/Janai2018ECCV.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://github.com/anuragranj/back2future.pytorch" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We propose a framework for unsupervised learning of optical flow and occlusions over multiple frames. Our multi-frame, occlusion-sensitive formulation outperforms existing unsupervised two-frame methods and even produces results on par with some fully supervised methods.</p>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2017</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/sintel_pyramid-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/sintel_pyramid-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/sintel_pyramid-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/sintel_pyramid.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="sintel_pyramid.png" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="ranjan2017optical" class="col-sm-8">
        <!-- Title -->
        <div class="title">Optical flow estimation using a spatial pyramid network</div>
        <!-- Author -->
        <div class="author">
        

        <em>Anurag Ranjan</em>, and Michael J Black</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, Sep 2017
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/1611.00850" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/anuragranj/spynet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="neog2017seeing" class="col-sm-8">
        <!-- Title -->
        <div class="title">Seeing Skin in Reduced Coordinates</div>
        <!-- Author -->
        <div class="author">
        

        Debanga R Neog, <em>Anurag Ranjan</em>, and Dinesh K Pai</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In IEEE International Conference on Automatic Face &amp; Gesture Recognition (FG)</em>, Sep 2017
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2016</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/about/assets/img/publication_preview/faces-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/about/assets/img/publication_preview/faces-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/about/assets/img/publication_preview/faces-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/about/assets/img/publication_preview/faces.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="faces.jpg" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="neog2016interactive" class="col-sm-8">
        <!-- Title -->
        <div class="title">Interactive gaze driven animation of the eye region</div>
        <!-- Author -->
        <div class="author">
        

        Debanga R Neog, João L Cardoso, <em>Anurag Ranjan</em>, and Dinesh K Pai</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Web3D Technology</em>, Sep 2016
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li></ol>
<h2 class="bibliography">2015</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="ranjan2015learning" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning periorbital soft tissue motion</div>
        <!-- Author -->
        <div class="author">
        

        <em>Anurag Ranjan</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>University of British Columbia,</em>, Sep 2015
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We model the soft tissues around the eyes that are associated with subtle and fast motions and convey emotions during facial expressions. Our data driven model that can efficiently learn and reproduce the complex motion of these periorbital soft tissues.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="neog2015gaze" class="col-sm-8">
        <!-- Title -->
        <div class="title">Gaze driven animation of eyes</div>
        <!-- Author -->
        <div class="author">
        

        Debanga Raj Neog, <em>Anurag Ranjan</em>, João L Cardoso, and Dinesh K Pai</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In ACM SIGGRAPH/Eurographics Symposium on Computer Animation</em>, Sep 2015
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="/about/assets/pdf/Gaze_driven_animation.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2012</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="bongale2012implementation" class="col-sm-8">
        <!-- Title -->
        <div class="title">Implementation of 3D object recognition and tracking</div>
        <!-- Author -->
        <div class="author">
        

        Pankaj Bongale, <em>Anurag Ranjan</em>, and Sahil Anand</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International conference on Recent Advances in Computing and Software Systems (RACSS)</em>, Sep 2012
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="/about/assets/pdf/bongale2012implementation.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li></ol>

</div>

          </article>
</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Anurag  Ranjan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="/about/assets/js/bootstrap.bundle.min.js"></script>
  <!-- <script src="/about/assets/js/mdb.min.js"></script> -->
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/about/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/about/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/about/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/about/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/about/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
